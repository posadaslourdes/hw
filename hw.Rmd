---
title: "machine learning"
author: "mlpm"
date: "30 de octubre de 2018"
output:
  word_document: default
  html_document: default
---
1.Data loading and tidy data

a. Check packages
b. Read Training and test data
c. Tidy data

```{r data}
#packages
#install.packages("caret")
#install.packages("randomForest")
#install.packages("rpart")
#install.packages("gbm")
#install.packages("e1071")
library(e1071)
library(gbm)
library(rpart.plot) # Decision Tree plot

library(caret)
library(randomForest) #Random forest for classification and regression
library(rpart) # Regressive Partitioning and Regression trees

#read data from web 

Url1 <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
Url2<- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

#tidy data: trasnformation to Na all strings variables NA, DIV/0!, deleting missing values and removing unnecesary columns

train <- read.csv(url(Url1), na.strings=c("NA","#DIV/0!",""))
test <- read.csv(url(Url2), na.strings=c("NA","#DIV/0!",""))

train<-train[,colSums(is.na(train)) == 0]
test <-test[,colSums(is.na(test)) == 0]

train <- train[,-c(1:6)]
test <- test[, -c(1:6)]

head(train)
summary(train$classe)
train$classe = factor(train$classe)
head(test)
summary(test$classe)
```

2. Models and prediction of variable classe
a.Reproducible: set seed
b.Data spliting (train) 70% in generation (training) and 30% validation sets(validation).
c.Generating model in generation set
d.Prediction in validation set
e. Summary of accuracy of models on predicting classe. Selection of best model looking to accuracy in the confusion matrix.And estimation of the out-of-sample error that is calculated as 1-accuracy 
The accuracy is the proportion of correct classified observation in training set. The expected accuracy is the expected accuracy in the test data set 
e. Prediction with selected model in test set


```{r models, echo=TRUE}
#set.seed(12345) 

training <- createDataPartition(train$classe, p = 0.70, list = FALSE)
validation <- train[-training, ]
train <- train[training, ]

#Models with generation set: random forest(rf),  Linear discriminant analysis (LDA), and Regressive Partitioning (rpart)
#while running 1st model an error ocurred
#install.packages("e1071")
library(e1071)
#models generation with different methods
mod1 <- train(classe ~ ., data=train, method="rf")
mod2 <- train(classe ~ ., data=train, method="lda")
mod3 <- train(classe ~ ., data=train, method="rpart")

importance(mod1)#see predictors importance
importance(mod2)
importance(mod3)
rm(training)
#prediction in validation set
pred1 <- predict(mod1, validation)
pred2 <- predict(mod2, validation)
pred3 <- predict(mod3, validation)

#Summary of accuracy of models on predicting classe: confusion matrices
confusionMatrix(pred1, validation$classe)
confusionMatrix(pred2, validation$classe)
confusionMatrix(pred3, validation$classe)
 ## Model 1 has the best accuracy 0.9964, this is the selected model  with an error of 0.0036
#FOR QUIZ
testprediction <- predict(mod1, test)
testprediction

#testprediction results
#  [1] B A B A A E D B A A B C B A E E A B B B
#Levels: A B C D E
```  
> confusionMatrix(pred1, validation$classe)
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1674    5    0    0    0
         B    0 1133    3    0    0
         C    0    1 1023    8    0
         D    0    0    0  956    4
         E    0    0    0    0 1078

Overall Statistics
                                          
               Accuracy : 0.9964          
                 95% CI : (0.9946, 0.9978)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9955          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9947   0.9971   0.9917   0.9963
Specificity            0.9988   0.9994   0.9981   0.9992   1.0000
Pos Pred Value         0.9970   0.9974   0.9913   0.9958   1.0000
Neg Pred Value         1.0000   0.9987   0.9994   0.9984   0.9992
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2845   0.1925   0.1738   0.1624   0.1832
Detection Prevalence   0.2853   0.1930   0.1754   0.1631   0.1832
Balanced Accuracy      0.9994   0.9971   0.9976   0.9954   0.9982
> confusionMatrix(pred2, validation$classe)
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1404  168   92   52   44
         B   39  728   99   47  166
         C  110  146  655  133   89
         D  112   45  144  694  103
         E    9   52   36   38  680

Overall Statistics
                                          
               Accuracy : 0.7071          
                 95% CI : (0.6952, 0.7187)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.6291          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.8387   0.6392   0.6384   0.7199   0.6285
Specificity            0.9155   0.9260   0.9016   0.9179   0.9719
Pos Pred Value         0.7977   0.6747   0.5781   0.6321   0.8344
Neg Pred Value         0.9345   0.9145   0.9219   0.9436   0.9207
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2386   0.1237   0.1113   0.1179   0.1155
Detection Prevalence   0.2991   0.1833   0.1925   0.1866   0.1385
Balanced Accuracy      0.8771   0.7826   0.7700   0.8189   0.8002
> confusionMatrix(pred3, validation$classe)
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1494  470  467  416   95
         B   21  380   29  184   90
         C  128  289  530  324  219
         D    0    0    0    0    0
         E   31    0    0   40  678

Overall Statistics
                                          
               Accuracy : 0.5237          
                 95% CI : (0.5109, 0.5365)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.3791          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.8925  0.33363  0.51657   0.0000   0.6266
Specificity            0.6561  0.93173  0.80243   1.0000   0.9852
Pos Pred Value         0.5078  0.53977  0.35570      NaN   0.9052
Neg Pred Value         0.9388  0.85350  0.88714   0.8362   0.9213
Prevalence             0.2845  0.19354  0.17434   0.1638   0.1839
Detection Rate         0.2539  0.06457  0.09006   0.0000   0.1152
Detection Prevalence   0.4999  0.11963  0.25319   0.0000   0.1273
Balanced Accuracy      0.7743  0.63268  0.65950   0.5000   0.8059




testprediction <- predict(mod1, test)
> testprediction
 [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E
> 
